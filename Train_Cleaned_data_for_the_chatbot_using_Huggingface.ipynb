{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Model : timpal0l/mdeberta-v3-base-squad2"
      ],
      "metadata": {
        "id": "IO-Ly4BF4B3C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwQrKQkqxIqU",
        "outputId": "c2489908-802a-4898-f527-0064a34ebed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTujbwZQ39Rp",
        "outputId": "a473fba9-dc35-45ce-fe1d-3e893f05e4ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface\n",
            "  Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: huggingface\n",
            "Successfully installed huggingface-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")\n",
        "question = \"Well, I thought we'd start with pronunciation, if that's okay with you\"\n",
        "context = \"Not the hacking, gagging and spitting part. Please.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOIkIE8y4Qxk",
        "outputId": "ca7b9948-0e7b-478a-ed3d-4e7527e3ac35"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 1.4742475286766421e-05,\n",
              " 'start': 0,\n",
              " 'end': 37,\n",
              " 'answer': 'Not the hacking, gagging and spitting'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")\n",
        "question = \"You're asking me out. That's so cute. What's your name again?\"\n",
        "context = \"Forget it.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vqn7s_M5N3B",
        "outputId": "31a5bc5b-1d6f-408e-ebe1-3feb03d984ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.00010793883120641112,\n",
              " 'start': 0,\n",
              " 'end': 10,\n",
              " 'answer': 'Forget it.'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")\n",
        "question = \"How is our little Find the Wench A Date plan progressing?\"\n",
        "context = \"Well, there's someone I think might be the one we've been looking for, the person who could potentially solve our problem.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDbT4j8a5dxS",
        "outputId": "2a7b9e4e-072d-402b-fedc-d49c048c547b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.002467111684381962,\n",
              " 'start': 5,\n",
              " 'end': 21,\n",
              " 'answer': \" there's someone\"}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")\n",
        "question = \"You have my word. As a gentleman\"\n",
        "context = \"You're sweet.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fvS9e-p5q63",
        "outputId": "aaea4710-28b4-4fc4-e6f7-38f1abb4ec5f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.0006007240735925734,\n",
              " 'start': 0,\n",
              " 'end': 13,\n",
              " 'answer': \"You're sweet.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")\n",
        "question = \"So that's the kind of guy she likes? Pretty ones?\"\n",
        "context = \"Who knows? All I've ever heard her say is that she'd dip before dating a guy that smokes.\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US4dMORb6IQs",
        "outputId": "d775c707-1920-450b-80c4-40fdaf0a9a0c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.2617480754852295, 'start': 81, 'end': 89, 'answer': ' smokes.'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")\n",
        "question = \"You know Chastity?\"\n",
        "context = \"I believe we share an art instructor\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7BwduIq6S68",
        "outputId": "5d00977a-736e-4e35-b27f-ec3cf19a081f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.005373140797019005,\n",
              " 'start': 0,\n",
              " 'end': 36,\n",
              " 'answer': 'I believe we share an art instructor'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}